# The pipeline is only run manually
variables:
  isManual: $[eq(variables['Build.Reason'], 'Manual')]

stages:
  - stage: gallery_redshift_all
    condition: eq(variables.isManual, true)
    pool:
      vmImage: 'ubuntu-20.04'

    jobs:
      - job: build_gallery
        timeoutInMinutes: 420
        variables:
          python.version: '3.8'
          GE_pytest_opts: ''

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - bash: python -m pip install --upgrade pip==21.3.1
            displayName: 'Update pip'

          - script: |
              pip install \
                "google-cloud-bigquery-storage" \
                "cryptography==38.0.4" \
                --requirement reqs/requirements-dev-all-contrib-expectations.txt \
                --editable "contrib/cli" \
                --editable ".[redshift]" \
                --constraint constraints-dev.txt
            displayName: 'Install dependencies'

          - bash: python ./build_gallery.py --backends "redshift" --outfile-name "expectation_library_v2--redshift_all_expectations.json" 2>&1 | tee output--build_gallery.txt ; grep -o "Took .* seconds to .*" output--build_gallery.txt | sort -k2,2nr > testing-times.txt ; grep -o "ERROR - (.*" output--build_gallery.txt | sort > testing-error-messages.txt; touch gallery-tracebacks.txt; grep -o "Expectation type.*" output--build_gallery.txt | sort > gallery-exp-types.txt
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Build Gallery'
            env:
              # snowflake credentials
              SNOWFLAKE_ACCOUNT: $(SNOWFLAKE_ACCOUNT)
              SNOWFLAKE_USER: $(SNOWFLAKE_USER)
              SNOWFLAKE_PW: $(SNOWFLAKE_PW)
              SNOWFLAKE_DATABASE: $(SNOWFLAKE_DATABASE)
              SNOWFLAKE_SCHEMA: $(SNOWFLAKE_SCHEMA)
              SNOWFLAKE_WAREHOUSE: $(SNOWFLAKE_WAREHOUSE)
              SNOWFLAKE_ROLE: $(SNOWFLAKE_ROLE)
              # redshift credentials
              REDSHIFT_USERNAME: $(REDSHIFT_USERNAME)
              REDSHIFT_PASSWORD: $(REDSHIFT_PASSWORD)
              REDSHIFT_HOST: $(REDSHIFT_HOST)
              REDSHIFT_PORT: $(REDSHIFT_PORT)
              REDSHIFT_DATABASE: $(REDSHIFT_DATABASE)
              REDSHIFT_SSLMODE: $(REDSHIFT_SSLMODE)
              # AWS credentials
              AWS_ACCESS_KEY_ID: $(AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(AWS_SECRET_ACCESS_KEY)
              AWS_DEFAULT_REGION: $(AWS_DEFAULT_REGION)
              ATHENA_DB_NAME: $(ATHENA_DB_NAME)
              ATHENA_STAGING_S3: $(ATHENA_STAGING_S3)
              ATHENA_DATA_BUCKET: $(ATHENA_DATA_BUCKET)
              ATHENA_TEN_TRIPS_DB_NAME: $(ATHENA_TEN_TRIPS_DB_NAME)
              # GCP credentials
              GOOGLE_APPLICATION_CREDENTIALS: $(gcp_authkey.secureFilePath)
              GE_TEST_GCP_PROJECT: $(GE_TEST_GCP_PROJECT)
              GE_TEST_BIGQUERY_DATASET: $(GE_TEST_BIGQUERY_DATASET)
              # Azure credentials
              AZURE_CREDENTIAL: $(AZURE_CREDENTIAL)
              AZURE_ACCESS_KEY: $(AZURE_ACCESS_KEY)

          - bash: grep -o "coverage_score:.*" output--build_gallery.txt | sort -k2,2nr
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show coverage scores'

          - bash: cut -d " " -f 3,4 gallery-exp-types.txt | uniq -c | sort -nr; echo; cut -d " " -f 3,4,6 gallery-exp-types.txt | sort
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show Expectation types and counts'

          - bash: grep -o "Implemented engines.*" output--build_gallery.txt
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show implemented engines'

          - bash: cat checklists.txt
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show full checklist summary'

          - bash: grep -E "(^expect|Completeness checklist|^ *[A-z]|^ *-|-----)" checklists.txt | grep -vE '(No validate_configuration|Using default validate_configuration|Has a full suite|Has passed a manual)'
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show checklist issues'

          - bash: cat testing-error-messages.txt
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show testing errors'

          - bash: grep --color -n -i warning -B 2 output--build_gallery.txt || echo "No warnings found"
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show testing warnings'

          - bash: cat gallery-tracebacks.txt
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show gallery tracebacks'

          - bash: grep "to df.to_sql" testing-times.txt || echo "No df.to_sql calls were made"
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show DataFrame to SQL times'

          - bash: grep "to run" testing-times.txt
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show testing times grouped by backend and Expectation'

          - bash: grep "to evaluate_json" testing-times.txt
            workingDirectory: $(Build.SourcesDirectory)/assets/scripts/
            displayName: 'Show testing times for individual tests'

          - task: S3Upload@1
            inputs:
              regionName: 'us-east-2'
              awsCredentials: 'aws-ci-great-expectations'
              bucketName: 'superconductive-public'
              sourceFolder: '$(Build.SourcesDirectory)/assets/scripts'
              globExpressions: '*.json'
              targetFolder: 'static/gallery/'
              filesAcl: 'public-read'
